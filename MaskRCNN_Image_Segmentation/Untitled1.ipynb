{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.idvscript import idvscript\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to Ballon trained weights\n",
    "BATTOL_WEIGHTS_PATH = \"/path/to/mask_rcnn_idv_0017.h5\"  # TODO: update this path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config =idvscript.IDVConfig()\n",
    "BOTTLE_DIR =\"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\samples\\\\idvscript\\\\dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load validation dataset\n",
    "dataset = idvscript.IDVDataset()\n",
    "dataset.load_idv(BOTTLE_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "weights_path = \"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\mask_rcnn_idv_0017.h5\"\n",
    "\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mrcnn.config\n",
    "import mrcnn.utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_car_boxes(boxes, class_ids):\n",
    "    car_boxes = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        # If the detected object isn't a car / truck, skip it\n",
    "        car_boxes.append(box)\n",
    "\n",
    "    return np.array(car_boxes)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "\n",
    "# Video file or camera to process - set this to 0 to use your webcam instead of a video file\n",
    "VIDEO_SOURCE = \"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\samples\\\\idvscript\\\\dataset\\\\val\\\\AC (4).jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Location of parking spaces\n",
    "parked_car_boxes = None\n",
    "\n",
    "# Load the video file we want to run detection on\n",
    "frame = cv2.imread(VIDEO_SOURCE)\n",
    "\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color\n",
    "rgb_image = frame[:, :, ::-1]\n",
    "\n",
    "    # Run the image through the Mask R-CNN model to get results.\n",
    "results = model.detect([rgb_image], verbose=0)\n",
    "\n",
    "    # Mask R-CNN assumes we are running detection on multiple images.\n",
    "    # We only passed in one image to detect, so only grab the first result.\n",
    "r = results[0]\n",
    "\n",
    "print(r['class_ids'])\n",
    "\n",
    "\n",
    "car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "\n",
    "print(\"found in frame of :\")\n",
    "\n",
    "    # Draw each box on the frame\n",
    "for box in car_boxes:\n",
    "    print(\"ob: \", box)\n",
    "\n",
    "    y1, x1, y2, x2 = box\n",
    "\n",
    "        # Draw the box\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    if r['class_ids'] in [1]:\n",
    "        BC=\"AC\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [2]:\n",
    "        BC=\"bottle\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [3]:\n",
    "        BC=\"laptop\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [4]:\n",
    "        BC=\"mobile\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [5]:\n",
    "        BC=\"Shoe\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [6]:\n",
    "        BC=\"watch\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)  \n",
    "\n",
    "\n",
    "    # Show the frame of video on the screen\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
