{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                19\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           idv\n",
      "NUM_CLASSES                    7\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Images: 91\n",
      "Classes: ['BG', '1', '2', '3', '4', '5', '6']\n",
      "Loading weights  D:\\Mask\\MaskRCNN_Image_Segmentation\\mask_rcnn_idv_0017.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-47c84d54574b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;31m# Convert the image from BGR color (which OpenCV uses) to RGB color\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m \u001b[0mrgb_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;31m# Run the image through the Mask R-CNN model to get results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.idvscript import idvscript\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to Ballon trained weights\n",
    "BATTOL_WEIGHTS_PATH = \"/path/to/mask_rcnn_idv_0017.h5\"  # TODO: update this path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config =idvscript.IDVConfig()\n",
    "BOTTLE_DIR =\"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\samples\\\\idvscript\\\\dataset\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load validation dataset\n",
    "dataset = idvscript.IDVDataset()\n",
    "dataset.load_idv(BOTTLE_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "weights_path = \"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\mask_rcnn_idv_0017.h5\"\n",
    "\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mrcnn.config\n",
    "import mrcnn.utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_car_boxes(boxes, class_ids):\n",
    "    car_boxes = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        # If the detected object isn't a car / truck, skip it\n",
    "        car_boxes.append(box)\n",
    "\n",
    "    return np.array(car_boxes)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "\n",
    "# Video file or camera to process - set this to 0 to use your webcam instead of a video file\n",
    "VIDEO_SOURCE = \"D:\\\\Mask\\\\MaskRCNN_Image_Segmentation\\\\samples\\\\idvscript\\\\dataset\\\\val\\\\mobile (30).jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Location of parking spaces\n",
    "parked_car_boxes = None\n",
    "\n",
    "# Load the video file we want to run detection on\n",
    "frame = cv2.imread(VIDEO_SOURCE)\n",
    "\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color\n",
    "rgb_image = frame[:, :, ::-1]\n",
    "\n",
    "    # Run the image through the Mask R-CNN model to get results.\n",
    "results = model.detect([rgb_image], verbose=0)\n",
    "\n",
    "    # Mask R-CNN assumes we are running detection on multiple images.\n",
    "    # We only passed in one image to detect, so only grab the first result.\n",
    "r = results[0]\n",
    "\n",
    "print(r['class_ids'])\n",
    "\n",
    "\n",
    "car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "\n",
    "print(\"found in frame of :\")\n",
    "\n",
    "    # Draw each box on the frame\n",
    "for box in car_boxes:\n",
    "    print(\"ob: \", box)\n",
    "\n",
    "    y1, x1, y2, x2 = box\n",
    "\n",
    "        # Draw the box\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    if r['class_ids'] in [1]:\n",
    "        BC=\"AC\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [2]:\n",
    "        BC=\"bottle\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [3]:\n",
    "        BC=\"laptop\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [4]:\n",
    "        BC=\"mobile\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [5]:\n",
    "        BC=\"Shoe\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)\n",
    "    \n",
    "    elif r['class_ids'] in [6]:\n",
    "        BC=\"watch\"\n",
    "        cv2.putText(frame, BC , (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),3,lineType=cv2.LINE_AA)  \n",
    "\n",
    "\n",
    "    # Show the frame of video on the screen\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
